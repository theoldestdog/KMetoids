{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second project using sales data for RFM features.\n",
    "Using log transformation on the full data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some conditions for data presentation.\n",
    "Limit floats to 2 decimal places and show all column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:20.2f}'.format\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data - note the encoding requirement due to condition of the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\alexd\\\\Python Projects\\\\k_means/online_retail_II_p2.csv\", encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results suggest the same issues as w/ the first project. Qty and Price have neg mins\n",
    "There are more unique descriptions than stock codes, so there will have to be checked and resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN Customer ID values - these get dropped\n",
    "df[df['Customer ID'].isna()].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for neg qty values\n",
    "# If they have a leading 'C' on the invoice they are returns and get dropped\n",
    "df[df['Quantity'] < 0].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the invoice column for other leaders/trailers to expected 6 digits\n",
    "# Use REGEX to find unique leaders - same as project 1 so drop C and A invoices\n",
    "\n",
    "df['Invoice'] = df['Invoice'].astype('str')\n",
    "df['Invoice'].str.replace(\"[0-9]\", \"\", regex=True).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the stockcodes for interesting things\n",
    "# Same result as in project 1 so only PADS will kept, the rest will be dropped\n",
    "\n",
    "df['StockCode'].astype('str')\n",
    "\n",
    "df[(df['StockCode'].str.match(\"^\\\\d{5}$\") == False) & (df['StockCode'].str.match(\"^\\\\d{5}[a-zA-Z]+$\") == False)][\"StockCode\"].unique()\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the data\n",
    "     Create new df for cleaned data\n",
    "     Drop NaN Customers\n",
    "     Drop 'C' and 'A' leader invoices\n",
    "     Drop all non-5 digit StockCodes except for PADS\n",
    "     Drop and check Price >= 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN customers\n",
    "cleaned_df.dropna(subset=['Customer ID'], inplace=True)\n",
    "cleaned_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop invoices with 'A' 'C' leaders\n",
    "cleaned_df['Invoice'] = cleaned_df['Invoice'].astype('str')\n",
    "\n",
    "mask = (\n",
    "    cleaned_df['Invoice'].str.match(\"^\\\\d{6}$\") == True\n",
    ")\n",
    "\n",
    "cleaned_df = cleaned_df[mask]\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the StockCodes\n",
    "\n",
    "cleaned_df['StockCode'] = cleaned_df['StockCode'].astype('str')\n",
    "\n",
    "mask = (\n",
    "    (cleaned_df['StockCode'].str.match(\"^\\\\d{5}\") == True)\n",
    "    | (cleaned_df['StockCode'].str.match(\"^\\\\d{5}[a-zA-Z]+$\") == True)\n",
    "    | (cleaned_df['StockCode'].str.match(\"^PADS$\") == True)  \n",
    ")\n",
    "\n",
    "cleaned_df = cleaned_df[mask]\n",
    "cleaned_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and Price >= 0\n",
    "len(cleaned_df[cleaned_df['Price'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df[cleaned_df['Price'] > 0.00]\n",
    "len(cleaned_df[cleaned_df['Price'] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of the original data remains after the data cleanup\n",
    "Dividing the cleaned_df by the original df reveals that 73.1 % of data is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_df) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the data\n",
    "First extend the Qty * Price into new column SalesLineTotal\n",
    "Then use groupby to group data by customer\n",
    "Recency uses the data lastest invoice date as max and subtracts the line last invoice date to determine 'since when'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df[\"SalesLineTotal\"] = cleaned_df[\"Quantity\"] * cleaned_df[\"Price\"]\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = cleaned_df.groupby(by=\"Customer ID\", as_index=False) \\\n",
    "    .agg(\n",
    "        MonetaryValue = (\"SalesLineTotal\", \"sum\"),\n",
    "        Frequency = (\"Invoice\", \"nunique\"),\n",
    "        LastInvoiceDate = (\"InvoiceDate\", \"max\")\n",
    "    )\n",
    "    \n",
    "aggregated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df[\"LastInvoiceDate\"] = pd.to_datetime(aggregated_df[\"LastInvoiceDate\"])\n",
    "\n",
    "max_invoice_date = aggregated_df[\"LastInvoiceDate\"].max()\n",
    "aggregated_df[\"Recency\"] = (max_invoice_date - aggregated_df[\"LastInvoiceDate\"]).dt.days\n",
    "\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the histograms since this data is likely the same as the previous year in having many extreme outliers in Monetary Value and Frequency\n",
    "Create boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=aggregated_df[\"MonetaryValue\"], color='lightgreen')\n",
    "plt.title('Box plot of Monetary Value')\n",
    "plt.xlabel('Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=aggregated_df[\"Frequency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Frequency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=aggregated_df[\"Recency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Recency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a log transformation on the full dataset to see if that eases the influence of the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_agg_df = aggregated_df.copy()\n",
    "log_agg_df['LastInvoiceDate'] = log_agg_df['LastInvoiceDate'].dt.date\n",
    "\n",
    "\n",
    "log_agg_df[\"MonetaryValue\"] = np.log1p(log_agg_df[\"MonetaryValue\"])\n",
    "log_agg_df[\"Frequency\"] = np.log1p(log_agg_df[\"Frequency\"])\n",
    "log_agg_df[\"Recency\"] = np.log1p(log_agg_df[\"Recency\"])\n",
    "log_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_agg_test_df = aggregated_df.copy()\n",
    "\n",
    "# Strip the timestamp and keep only the date\n",
    "log_agg_test_df['DateOnly'] = log_agg_test_df['LastInvoiceDate'].dt.date\n",
    "\n",
    "# Convert the date to the number of days since January 1, 1970\n",
    "log_agg_test_df['DateAsFloat'] = (pd.to_datetime(log_agg_test_df['DateOnly']) - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1D')\n",
    "\n",
    "log_agg_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=log_agg_df[\"MonetaryValue\"], color='lightgreen')\n",
    "plt.title('Box plot of Monetary Value')\n",
    "plt.xlabel('Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=log_agg_df[\"Frequency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Frequency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=log_agg_df[\"Recency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Recency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log transformation did help but there is still a profound effect of the Monetary Value and Frequency high outliers.\n",
    "Use a 3-D scatterplot to check the scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(log_agg_df[\"MonetaryValue\"], log_agg_df[\"Frequency\"], log_agg_df[\"Recency\"])\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "ax.set_title('3-D Scatterplot of Log Aggregated Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log transformation moves the data closer together and moves it to the centre but adding a scaling should normalize the data for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_agg_df = log_agg_df.drop('LastInvoiceDate', axis=1)\n",
    "log_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(log_agg_df)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaler returns a Numpy array that has to be worked back into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_log_data_df = pd.DataFrame(scaled_data, index=log_agg_df.index,\n",
    "                        columns=('Customer ID', 'MonetaryValue', 'Frequency', 'Recency'))\n",
    "scaled_log_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting out a Numpy problem digesting a date.time column generating the KMeans result\n",
    "    log_agg_df['LastInvoiceDate'] = log_agg_df['datetime_column'].apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan)\n",
    "Convert datetime_column to string\n",
    "    log_agg_df['LastInvoiceDate'] = log_agg_df['LastInvoiceDate'].astype(str)\n",
    "Convert datetime_column to object\n",
    "    log_agg_df['LastInvoiceDate'] = log_agg_df['LastInvoiceDate'].astype('object')\n",
    "Peel off the time stamp\n",
    "    log_agg_df['LastInvoiceDate'] = log_agg_df['LastInvoiceDate'].dt.date\n",
    "Convert date to Julian number as float as of 01January1970 The \n",
    "    log_agg_test_df['DateAsFloat'] = (pd.to_datetime(log_agg_test_df['DateOnly']) - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "max_k = 12\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "k_values = range(2, max_k + 1)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters = k, random_state = 42, max_iter = 1000)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_log_data_df)\n",
    "    sil_score = silhouette_score(scaled_log_data_df, cluster_labels)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.title('Kmeans Inertia for Different Values of (k)')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_values, silhouette_scores, marker='o', color='orange')\n",
    "plt.title('Silhouette Scores for Different Values of (k)')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the KMeans cluster run suggests 4 clusters is the optimal choice on the elbow.\n",
    "This is supported by the silhouette score where 4 scores hight than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42, max_iter=1000)\n",
    "cluster_labels = kmeans.fit_predict(scaled_log_data_df)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_log_data_df['Cluster'] = cluster_labels\n",
    "scaled_log_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-D plot of cluster results to see how the clusters are mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {\n",
    "    0: '#1f77b4', # Blue\n",
    "    1: '#ff7f0e', # Orange\n",
    "    2: '#2ca02c', # Green\n",
    "    3: '#d62728', # Red\n",
    "}\n",
    "\n",
    "colors = scaled_log_data_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(scaled_log_data_df['MonetaryValue'],\n",
    "               scaled_log_data_df['Frequency'],\n",
    "               scaled_log_data_df['Recency'],\n",
    "               c=colors,\n",
    "               marker='o')\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "ax.set_title('3-D Scatterplot of Log Transformed & Std Scaled Customer data by Cluster')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data using MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "mm_scaled_log_data = scaler.fit_transform(log_agg_df)\n",
    "mm_scaled_log_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the numpy array and bring in back into pandas as a new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaled_log_data_df = pd.DataFrame(mm_scaled_log_data, index=log_agg_df.index,\n",
    "                        columns=('Customer ID', 'MonetaryValue', 'Frequency', 'Recency'))\n",
    "mm_scaled_log_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run KMeans on the new scaled df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42, max_iter=1000)\n",
    "cluster_labels = kmeans.fit_predict(mm_scaled_log_data)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaled_log_data_df['Cluster'] = cluster_labels\n",
    "mm_scaled_log_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-D Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {\n",
    "    0: '#1f77b4', # Blue\n",
    "    1: '#ff7f0e', # Orange\n",
    "    2: '#2ca02c', # Green\n",
    "    3: '#d62728', # Red\n",
    "}\n",
    "\n",
    "colors = mm_scaled_log_data_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(mm_scaled_log_data_df['MonetaryValue'],\n",
    "               mm_scaled_log_data_df['Frequency'],\n",
    "               mm_scaled_log_data_df['Recency'],\n",
    "               c=colors,\n",
    "               marker='o')\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "ax.set_title('3-D Scatterplot of Log Transformed & MinMax Scaled Customer data by Cluster')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaling in MinMax is consistent from feature to feature to feature so proceed w/ this scaled data.\n",
    "Visualize w/ violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.violinplot(x=mm_scaled_log_data_df['Cluster'], y=mm_scaled_log_data_df['MonetaryValue'], palette=cluster_colors,\n",
    "                hue=mm_scaled_log_data_df['Cluster'])\n",
    "sns.violinplot(mm_scaled_log_data_df['MonetaryValue'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Monetary Value Feature by Cluster(k): Full Data Set Transformed and MinMax Scaled')\n",
    "plt.ylabel('Monetary Value')\n",
    "\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.violinplot(x=mm_scaled_log_data_df['Cluster'], y=mm_scaled_log_data_df['Frequency'], palette=cluster_colors,\n",
    "                hue=mm_scaled_log_data_df['Cluster'])\n",
    "sns.violinplot(mm_scaled_log_data_df['Frequency'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Frequency Featue by Cluster(k): Full Data Set Transformed and MinMax Scaled')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.violinplot(x=mm_scaled_log_data_df['Cluster'], y=mm_scaled_log_data_df['Recency'], palette=cluster_colors,\n",
    "                hue=mm_scaled_log_data_df['Cluster'])\n",
    "sns.violinplot(mm_scaled_log_data_df['Recency'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Recency Featue by Cluster(k): Full Data Set Transformed and MinMax Scaled')\n",
    "plt.ylabel('Recency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to the aggregated data df and rework the data to remove and preserve the outliers.\n",
    "Process both data sets though scaling and then to KMeans and determine the differences between \n",
    "the segmented data feature results and the features of the entire data set log transformed and scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the boxplots of the aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=aggregated_df[\"MonetaryValue\"], color='lightgreen')\n",
    "plt.title('Box plot of Monetary Value')\n",
    "plt.xlabel('Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=aggregated_df[\"Frequency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Frequency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=aggregated_df[\"Recency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Recency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplots show the outliers well beyond the 1.5 *  +IQR\n",
    "Remove the high outliers from MonetaryValue and Frequency and re-plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Q3 = aggregated_df['MonetaryValue'].quantile(0.75)\n",
    "M_Q1 = aggregated_df['MonetaryValue'].quantile(0.25)\n",
    "M_IQR = M_Q3 - M_Q1\n",
    "M_HO = M_Q3 + 1.5 * M_IQR\n",
    "M_LO = M_Q1 - 1.5 * M_IQR\n",
    "high_mvo_df = aggregated_df[(aggregated_df['MonetaryValue'] > M_HO)].copy()\n",
    "all_mvo_df = aggregated_df[(aggregated_df['MonetaryValue'] > M_HO)\n",
    "                           | (aggregated_df['MonetaryValue'] < M_LO)].copy()\n",
    "\n",
    "all_mvo_df = all_mvo_df.drop([\"LastInvoiceDate\"], axis=1)\n",
    "all_mvo_df\n",
    "\n",
    "#high_mvo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_Q3 = aggregated_df['Frequency'].quantile(0.75)\n",
    "F_Q1 = aggregated_df['Frequency'].quantile(0.25)\n",
    "F_IQR = F_Q3 - F_Q1\n",
    "F_HO = F_Q3 + 1.5 * F_IQR\n",
    "F_LO = F_Q1 - 1.5 * F_IQR\n",
    "high_fo_df = aggregated_df[(aggregated_df['Frequency'] > F_HO)].copy()\n",
    "\n",
    "all_fo_df = aggregated_df[(aggregated_df['Frequency'] > F_HO)\n",
    "                           | (aggregated_df['Frequency'] < F_LO)].copy()\n",
    "\n",
    "all_fo_df = all_fo_df.drop([\"LastInvoiceDate\"], axis=1)\n",
    "all_fo_df\n",
    "#high_fo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove those outliers and create a new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outliers_df = aggregated_df[(~aggregated_df.index.isin(high_mvo_df.index)) & \n",
    "                                (~aggregated_df.index.isin(high_fo_df.index))]\n",
    "\n",
    "\n",
    "non_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all of the Monetary Value and Frequency outliers and create a new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers_out_df = aggregated_df[(~aggregated_df.index.isin(all_mvo_df.index)) & \n",
    "                                (~aggregated_df.index.isin(all_fo_df.index))]\n",
    "\n",
    "all_outliers_out_df = all_outliers_out_df.drop(['LastInvoiceDate'], axis=1)\n",
    "\n",
    "all_outliers_out_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the boxplots on the non outlier dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=non_outliers_df[\"MonetaryValue\"], color='lightgreen')\n",
    "plt.title('Box plot of Monetary Value')\n",
    "plt.xlabel('Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=non_outliers_df[\"Frequency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Frequency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=non_outliers_df[\"Recency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Recency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go with this result and scale the data and look at results\n",
    "First drop the LastInvoiceDate column as it is not needed going forward\n",
    "Use StandardScaler to scale the data\n",
    "Build new scaled df\n",
    "3-D plot the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outliers_df = non_outliers_df.drop('LastInvoiceDate', axis=1)\n",
    "non_outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(non_outliers_df[['MonetaryValue', 'Frequency', 'Recency']])\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_scaled_data_df =pd.DataFrame(scaled_data, index=non_outliers_df.index,\n",
    "                                columns=('MonetaryValue', 'Frequency', 'Recency'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(ss_scaled_data_df['MonetaryValue'],\n",
    "               ss_scaled_data_df['Frequency'],\n",
    "               ss_scaled_data_df['Recency'],\n",
    "               marker='o')\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "ax.set_title('3-D Scatterplot of Log Transformed & MinMax Scaled Customer data by Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is clustered over on the right side of the plot but the scaling is reasonable so use this scaled data for KMeans.\n",
    "\n",
    "Assume that 4 clusters to be used for this KMeans procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42, max_iter=1000)\n",
    "cluster_labels = kmeans.fit_predict(ss_scaled_data_df)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_scaled_data_df['Cluster'] = cluster_labels\n",
    "ss_scaled_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-D plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {\n",
    "    0: '#1f77b4', # Blue\n",
    "    1: '#ff7f0e', # Orange\n",
    "    2: '#2ca02c', # Green\n",
    "    3: '#d62728', # Red\n",
    "}\n",
    "\n",
    "colors = ss_scaled_data_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(ss_scaled_data_df['MonetaryValue'],\n",
    "               ss_scaled_data_df['Frequency'],\n",
    "               ss_scaled_data_df['Recency'],\n",
    "               c=colors,\n",
    "               marker='o')\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "ax.set_title('3-D Scatterplot of Non-High Outlier Std Scaled Customer data by Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3-D plot looks good so proceed to the Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.violinplot(x=ss_scaled_data_df['Cluster'], y=ss_scaled_data_df['MonetaryValue'], palette=cluster_colors,\n",
    "                hue=ss_scaled_data_df['Cluster'])\n",
    "sns.violinplot(ss_scaled_data_df['MonetaryValue'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Monetary Value Feature by Cluster(k): High Outlier removed Std Scaled')\n",
    "plt.ylabel('Monetary Value')\n",
    "\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.violinplot(x=ss_scaled_data_df['Cluster'], y=ss_scaled_data_df['Frequency'], palette=cluster_colors,\n",
    "                hue=ss_scaled_data_df['Cluster'])\n",
    "sns.violinplot(ss_scaled_data_df['Frequency'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Frequency Featue by Cluster(k): High Outlier removed Std Scaled')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.violinplot(x=ss_scaled_data_df['Cluster'], y=ss_scaled_data_df['Recency'], palette=cluster_colors,\n",
    "                hue=ss_scaled_data_df['Cluster'])\n",
    "sns.violinplot(ss_scaled_data_df['Recency'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Recency Featue by Cluster(k): High Outlier removed Std Scaled')\n",
    "plt.ylabel('Recency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the df with all outliers removed through scaling and KMeans to check and compare the results\n",
    "Scatterplot the non-outlier data\n",
    "Scale the data\n",
    "Scatterplot the results\n",
    "KMeans\n",
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=all_outliers_out_df[\"MonetaryValue\"], color='lightgreen')\n",
    "plt.title('Box plot of Monetary Value: Non-outlier')\n",
    "plt.xlabel('Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=all_outliers_out_df[\"Frequency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Frequency: Non-outlier')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=all_outliers_out_df[\"Recency\"], color='skyblue')\n",
    "plt.xlabel('Boxplot of Recency: Non-outlier')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Standard Scaler to scale the data and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(all_outliers_out_df[['MonetaryValue', 'Frequency', 'Recency']])\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outlier_scaled_data_df = pd.DataFrame(scaled_data, index=all_outliers_out_df.index,\n",
    "                            columns=('MonetaryValue', 'Frequency', 'Recency'))\n",
    "no_outlier_scaled_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-D Plot of scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(no_outlier_scaled_data_df['MonetaryValue'],\n",
    "               no_outlier_scaled_data_df['Frequency'],\n",
    "               no_outlier_scaled_data_df['Recency'],\n",
    "               marker='o')\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "ax.set_title('3-D Scatterplot of Std Scaled Customer data No Outliers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans on scaled data and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42, max_iter=1000)\n",
    "cluster_labels = kmeans.fit_predict(no_outlier_scaled_data_df)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outlier_scaled_data_df['Cluster'] = cluster_labels\n",
    "no_outlier_scaled_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = {\n",
    "    0: '#1f77b4', # Blue\n",
    "    1: '#ff7f0e', # Orange\n",
    "    2: '#2ca02c', # Green\n",
    "    3: '#d62728', # Red\n",
    "}\n",
    "\n",
    "colors = no_outlier_scaled_data_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(no_outlier_scaled_data_df['MonetaryValue'],\n",
    "               no_outlier_scaled_data_df['Frequency'],\n",
    "               no_outlier_scaled_data_df['Recency'],\n",
    "               c=colors,\n",
    "               marker='o')\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "ax.set_title('3-D Scatterplot of No Outlier Std Scaled Customer data by Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violin Plots of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.violinplot(x=no_outlier_scaled_data_df['Cluster'], y=no_outlier_scaled_data_df['MonetaryValue'], palette=cluster_colors,\n",
    "                hue=no_outlier_scaled_data_df['Cluster'])\n",
    "sns.violinplot(no_outlier_scaled_data_df['MonetaryValue'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Monetary Value Feature by Cluster(k): All Outliers removed Std Scaled')\n",
    "plt.ylabel('Monetary Value')\n",
    "\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.violinplot(x=no_outlier_scaled_data_df['Cluster'], y=no_outlier_scaled_data_df['Frequency'], palette=cluster_colors,\n",
    "                hue=no_outlier_scaled_data_df['Cluster'])\n",
    "sns.violinplot(no_outlier_scaled_data_df['Frequency'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Frequency Featue by Cluster(k): All Outliers removed Std Scaled')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.violinplot(x=no_outlier_scaled_data_df['Cluster'], y=no_outlier_scaled_data_df['Recency'], palette=cluster_colors,\n",
    "                hue=no_outlier_scaled_data_df['Cluster'])\n",
    "sns.violinplot(no_outlier_scaled_data_df['Recency'], color='gray', linewidth=1.0)\n",
    "plt.title('Violin Plot of Recency Featue by Cluster(k): All Outliers removed Std Scaled')\n",
    "plt.ylabel('Recency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
