{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project to perform RFM Analysis on sales dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:20.2f}'.format\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the csv data file and check loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\alexd\\\\Python Projects\\\\k_means/online_retail_II_p1.csv\", encoding='ISO-8859-1')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problems observed above - Qty and Price both have neg mins - check these\n",
    "number of customer ids is many less than the qty/price count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problems from above - unique stock codes <> description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Customer ID for NaN - this are of no value and will be dropped\n",
    "df[df['Customer ID'].isna()].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for neg Qty - 'C' means that the order was cancelled or returned - these will be excluded\n",
    "df[df['Quantity'] < 0].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the Invoice column to string and check for other alpha leaders\n",
    "# Use REGEX to find the leaders ^ and $ as anchors //d for digits\n",
    "df['Invoice'] = df['Invoice'].astype(\"str\")\n",
    "df[df['Invoice'].str.match(\"^\\\\d{6}$\") == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how what alpha leaders there are. Use REGEX to scrub off numbers and show unique what's left\n",
    "df[\"Invoice\"].str.replace(\"[0-9]\", \"\", regex=True).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know 'C' is cancel, check what 'A' denotes\n",
    "# A denote bad debt so both C and A will be dropped\n",
    "df[df[\"Invoice\"].str.startswith(\"A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the StockCodes for interesting things\n",
    "# Cast StockCode as string to start\n",
    "# Use REGEX to find anomalies to the StockCode that should be 5 digits\n",
    "df['StockCode'] = df['StockCode'].astype('str')\n",
    "df[(df['StockCode'].str.match(\"^\\\\d{5}$\") == False) & (df['StockCode'].str.match(\"^\\\\d{5}[a-zA-Z]+$\") == False)][\"StockCode\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's pile of non-conforming StockCodes. Each has to be investigated.\n",
    "The code line below is the iterative process of keep/drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"StockCode\"].str.contains(\"DOT\")]\n",
    "# DOT is of no value and would be dropped\n",
    "# after going through the list only PADS is going to be kept, the rest dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"StockCode\"].str.contains(\"PADS\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the Invoice column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['Invoice'] = cleaned_df['Invoice'].astype('str')\n",
    "\n",
    "mask = (\n",
    "    cleaned_df['Invoice'].str.match(\"^\\\\d{6}$\") == True   \n",
    ")\n",
    "cleaned_df = cleaned_df[mask]\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the StockCode column\n",
    "Three matches to keep 1. 5 digit stock codes 2. 5 digit stock codes with alpha follower 3. StockCode = PADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['StockCode'] = cleaned_df['StockCode'].astype('str')\n",
    "\n",
    "mask = (\n",
    "    (cleaned_df['StockCode'].str.match(\"^\\\\d{5}$\") == True)\n",
    "    | (cleaned_df[\"StockCode\"].str.match(\"^\\\\d{5}[a-zA-Z]+$\") == True)\n",
    "    | (cleaned_df['StockCode'].str.match(\"^PADS$\") == True)\n",
    ")\n",
    "\n",
    "cleaned_df = cleaned_df[mask]\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the lines w/ Customer ID = NaN\n",
    "After dropping the Customer ID NaNs the counts should line up Price/Qty/Customer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.dropna(subset=['Customer ID'], inplace=True)\n",
    "cleaned_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Price where price = 0\n",
    "# How many 0 entries - 28\n",
    "len(cleaned_df[cleaned_df[\"Price\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df[cleaned_df[\"Price\"] > 0.0]\n",
    "len(cleaned_df[cleaned_df[\"Price\"] == 0])  ## 0 entries w/ price = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data left/lost in data cleanup\n",
    "77% is left so 23% of data lost during cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_df) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the data into RFM features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the Price and Quantity into Sales Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['SalesLineTotal'] = cleaned_df['Quantity'] * cleaned_df['Price']\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new df for aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = cleaned_df.groupby(by='Customer ID', as_index=False) \\\n",
    "    .agg(\n",
    "        MonetaryValue=(\"SalesLineTotal\", \"sum\"),\n",
    "        Frequency= (\"Invoice\", \"nunique\"),\n",
    "        LastInvoiceDate=(\"InvoiceDate\", \"max\")\n",
    "    )\n",
    "    \n",
    "aggregated_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Recency by using max date and lastest date of invoice\n",
    "Set LastInvoiceDate to type datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df['LastInvoiceDate'] = pd.to_datetime(aggregated_df['LastInvoiceDate'])\n",
    "max_invoice_date = aggregated_df[\"LastInvoiceDate\"].max()\n",
    "aggregated_df[\"Recency\"] = (max_invoice_date - aggregated_df['LastInvoiceDate']).dt.days\n",
    "\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize with histograms and box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=( 15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(aggregated_df['MonetaryValue'], bins=10, color='lightgreen', edgecolor='black')\n",
    "plt.title('Monetary Value Distribution')\n",
    "plt.xlabel(' Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(aggregated_df['Frequency'], bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Frequency Distribution')\n",
    "plt.xlabel(' Frequency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(aggregated_df['Recency'], bins=10, color='salmon', edgecolor='black')\n",
    "plt.title('Recency Distribution')\n",
    "plt.xlabel(' Recency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=( 15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=aggregated_df['MonetaryValue'], color='lightgreen')\n",
    "plt.title('Monetary Value Boxplot')\n",
    "plt.xlabel(' Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=aggregated_df['Frequency'], color='skyblue')\n",
    "plt.title('Frequency Boxplot')\n",
    "plt.xlabel(' Frequency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=aggregated_df['Recency'], color='salmon')\n",
    "plt.title('Recency Boxplot')\n",
    "plt.xlabel(' Recency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows little distribution with so much of the data at the bottom of the plot.\n",
    "This is confirmed by the boxplot that shows the large number of big outliers in the MV and Freq columns\n",
    "These outliers are important to the data set so they will be removed but saved to process on their own\n",
    "\n",
    "monetary_outliers_df = aggregated_df[(aggregated_df[\"MonetaryValue\"] > (M_Q3 + 1.5 * M_IQR)) | (aggregated_df[\"MonetaryValue\"] < (M_Q1 - 1.5 * M_IQR))].copy()\n",
    "\n",
    "monetary_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Monetary outliers = 423\n",
    "\n",
    "M_Q1 = aggregated_df['MonetaryValue'].quantile(0.25)\n",
    "M_Q3 = aggregated_df['MonetaryValue'].quantile(0.75)\n",
    "M_IQR = M_Q3 - M_Q1\n",
    "monetary_outliers_df = aggregated_df[(aggregated_df['MonetaryValue'] > (M_Q3 + 1.5 * M_IQR)) \n",
    "                                     | (aggregated_df['MonetaryValue'] < (M_Q1 - 1.5 * M_IQR))].copy()\n",
    "\n",
    "monetary_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Frequency outliers = 279\n",
    "\n",
    "F_Q1 = aggregated_df['Frequency'].quantile(0.25)\n",
    "F_Q3 = aggregated_df['Frequency'].quantile(0.75)\n",
    "F_IQR = F_Q3 -F_Q1\n",
    "frequency_outliers_df = aggregated_df[(aggregated_df['Frequency'] > (F_Q3 + 1.5 * F_IQR)) \n",
    "                                     | (aggregated_df['Frequency'] < (F_Q1 - 1.5 * F_IQR))].copy()\n",
    "\n",
    "frequency_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the outliers out of the aggregated_df\n",
    "Create a new df and use ~ meaning 'not' from the two outlier df's using their indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outliers_df = aggregated_df[(~aggregated_df.index.isin(monetary_outliers_df.index)) & \n",
    "                                (~aggregated_df.index.isin(frequency_outliers_df.index))]\n",
    "\n",
    "non_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the boxplots - they do show the difference once the extreme number of outliers are removed\n",
    "\n",
    "plt.figure(figsize=( 15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=non_outliers_df['MonetaryValue'], color='lightgreen')\n",
    "plt.title('Monetary Value Boxplot')\n",
    "plt.xlabel(' Monetary Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=non_outliers_df['Frequency'], color='skyblue')\n",
    "plt.title('Frequency Boxplot')\n",
    "plt.xlabel(' Frequency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=non_outliers_df['Recency'], color='salmon')\n",
    "plt.title('Recency Boxplot')\n",
    "plt.xlabel(' Recency')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D Scatterplot of Customer Data\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "scatter = ax.scatter(non_outliers_df['MonetaryValue'], non_outliers_df['Frequency'], non_outliers_df['Recency'])\n",
    "\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "\n",
    "ax.set_title('3_D Scatter Plot of Customer Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scaling\n",
    "\n",
    "The 3-D plot shows the data distribution but the axes show that the data is on 3 different scales each seperated by an order of magnitude - 10/100/1000\n",
    "To properly work the data it needs to be scaled so that the each data axis is on a common scale\n",
    "Standard Scaler forces all data onto a scale to a mean of 0 and a std dev of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(non_outliers_df[['MonetaryValue', 'Frequency', 'Recency']])\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_data is returned as a numpy array and it needs to be returned to new df\n",
    "scaled_data_df = pd.DataFrame(scaled_data, index=non_outliers_df.index,\n",
    "                columns=(\"MonetaryValue\", \"Frequency\", \"Recency\"))\n",
    "scaled_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New 3-D Scatterplot of Scaled Customer Data\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "scatter = ax.scatter(scaled_data_df['MonetaryValue'], scaled_data_df['Frequency'], scaled_data_df['Recency'])\n",
    "\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "\n",
    "ax.set_title('3_D Scatter Plot of Scaled Customer Data')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans Clustering\n",
    "First determine the number of clusters by letting the method run on k clusters and capture inertia\n",
    "Determine the most likely number of clusters using the 'Elbow' method\n",
    "Confirm choice using silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "max_k =12\n",
    "\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "k_values = range(2, max_k + 1) # work from 2 - 12 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42, max_iter=1000)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_data_df)\n",
    "    sil_score = silhouette_score(scaled_data_df, cluster_labels)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.title('KMeans Inertia for Different Values of k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_values, silhouette_scores, marker='o', color='orange')\n",
    "plt.title('Silhouette Scores for Different Values of k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KMeans test and the silhouette score suggests that 4 clusters would be the most useful for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42, max_iter=1000)\n",
    "cluster_labels = kmeans.fit_predict(scaled_data_df)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cluster labels to non_outlier_df for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outliers_df['Cluster'] = cluster_labels\n",
    "non_outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3-D of cluster id'd by color map\n",
    "cluster_colors = {0: '#1f77b4', #Blue\n",
    "                  1: '#ff7f0e', # Orange\n",
    "                  2: '#2ca02c', # Green\n",
    "                  3: '#d62728', # Red\n",
    "                  }\n",
    "\n",
    "colors = non_outliers_df['Cluster'].map(cluster_colors)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scatter = ax.scatter(non_outliers_df['MonetaryValue'],\n",
    "                     non_outliers_df['Frequency'],\n",
    "                     non_outliers_df['Recency'],\n",
    "                     c=colors,\n",
    "                     marker='o')\n",
    "\n",
    "ax.set_xlabel('Monetary Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_zlabel('Recency')\n",
    "\n",
    "ax.set_title(' 3D Scatterplot of Customer Data by Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Violin plots of the clusters to determine placing in features\n",
    "The gray violin plot is the non-scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.violinplot(x=non_outliers_df['Cluster'], y=non_outliers_df['MonetaryValue'], palette=cluster_colors, \n",
    "             hue=non_outliers_df['Cluster'])\n",
    "sns.violinplot(y=non_outliers_df['MonetaryValue'], color='gray', linewidth=1.0)\n",
    "plt.title('Monetary Value by Cluster')\n",
    "plt.ylabel('Monetary Value')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.violinplot(x=non_outliers_df['Cluster'], y=non_outliers_df['Frequency'], palette=cluster_colors, \n",
    "             hue=non_outliers_df['Cluster'])\n",
    "sns.violinplot(y=non_outliers_df['Frequency'], color='gray', linewidth=1.0)\n",
    "plt.title('Frequency by Cluster')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.violinplot(x=non_outliers_df['Cluster'], y=non_outliers_df['Recency'], palette=cluster_colors, \n",
    "             hue=non_outliers_df['Cluster'])\n",
    "sns.violinplot(y=non_outliers_df['Recency'], color='gray', linewidth=1.0)\n",
    "plt.title('Recency by Cluster')\n",
    "plt.ylabel('Recency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0 = Blue - high value and buy often - work to retain this cluster\n",
    "Cluster 1 = Orange - low value/frequency but recent buyers - work to keep them buying\n",
    "Cluster 2 = Green - least active and low value somewhat recent - work to get them back\n",
    "Cluster 3 = Red - highest value and frequent buyers but not recent - work to keep them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the outliers from their dfs into one df to visualize their features\n",
    "Do this by defining a variable that captures all of the overlap indicies using index.intersection \n",
    "Next drop the indicies in the variable from the two outlier dfs\n",
    "Then concatenating the three elements into a new df\n",
    "Manually assign clusters to each outlier feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the overlap indicies and drop from existing dfs\n",
    "overlap_indicies = monetary_outliers_df.index.intersection(frequency_outliers_df.index)\n",
    "\n",
    "frequency_only_outliers = frequency_outliers_df.drop(overlap_indicies)\n",
    "monetary_only_outliers = monetary_outliers_df.drop(overlap_indicies)\n",
    "monetary_and_frequency_outliers = monetary_outliers_df.loc[overlap_indicies]\n",
    "\n",
    "monetary_only_outliers['Cluster'] = -1\n",
    "frequency_only_outliers['Cluster'] = -2\n",
    "monetary_and_frequency_outliers['Cluster'] = -3\n",
    "\n",
    "outlier_clusters_df = pd.concat([monetary_only_outliers, frequency_only_outliers, \n",
    "                                 monetary_and_frequency_outliers])\n",
    "\n",
    "outlier_clusters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the features using the assigned clusters and violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = { -1: '#9467bd',\n",
    "                  -2: '#8c564b', \n",
    "                  -3: '#e377c2'\n",
    "                  }\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.violinplot(x=outlier_clusters_df['Cluster'], y=outlier_clusters_df['MonetaryValue'], palette=cluster_colors, \n",
    "             hue=outlier_clusters_df['Cluster'])\n",
    "sns.violinplot(y=outlier_clusters_df['MonetaryValue'], color='gray', linewidth=1.0)\n",
    "plt.title('Monetary Value by Cluster')\n",
    "plt.ylabel('Monetary Value')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.violinplot(x=outlier_clusters_df['Cluster'], y=outlier_clusters_df['Frequency'], palette=cluster_colors, \n",
    "             hue=outlier_clusters_df['Cluster'])\n",
    "sns.violinplot(y=outlier_clusters_df['Frequency'], color='gray', linewidth=1.0)\n",
    "plt.title('Frequency by Cluster')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.violinplot(x=outlier_clusters_df['Cluster'], y=outlier_clusters_df['Recency'], palette=cluster_colors, \n",
    "             hue=outlier_clusters_df['Cluster'])\n",
    "sns.violinplot(y=outlier_clusters_df['Recency'], color='gray', linewidth=1.0)\n",
    "plt.title('Recency by Cluster')\n",
    "plt.ylabel('Recency')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster -1 Monetary outliers - hi $ but low frequency - work on keeping them and encourage purchases\n",
    "Cluster - 2 Frequency outliers - lower $ but more frequent purchases - try to increase value spending\n",
    "Cluster -3 Monetary and Frequency outliers - hi $ and hi frequency - develop strategies to keep them engaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = {\n",
    "    0: \"0-Retain\",\n",
    "    1: \"1-Re-engage\",\n",
    "    2: \"2-Nurture\",\n",
    "    3: \"3-Reward\",\n",
    "    -1: \"OM-Pamper\",\n",
    "    -2: \"OF-Upsell\",\n",
    "    -3: \"OMF-Delight\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both outlier and non_outlier dfs together into a full clustering df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_clustering_df = pd.concat([non_outliers_df, outlier_clusters_df])\n",
    "full_clustering_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column and assign cluster_labels by mapping label to cluster\n",
    "full_clustering_df[\"ClusterLabel\"] = full_clustering_df[\"Cluster\"].map(cluster_labels)\n",
    "\n",
    "full_clustering_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = full_clustering_df['ClusterLabel'].value_counts()\n",
    "\n",
    "full_clustering_df[\"MonetaryValue per 100 pounds\"] = full_clustering_df[\"MonetaryValue\"] / 100.00\n",
    "feature_means = full_clustering_df.groupby('ClusterLabel')[['Recency', 'Frequency', 'MonetaryValue per 100 pounds']].mean()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "sns.barplot(x=cluster_counts.index, y=cluster_counts.values, ax=ax1, palette='viridis', hue=cluster_counts.index)\n",
    "ax1.set_ylabel('Number of Customers', color='b')\n",
    "ax1.set_title('Cluster Distribution with Average Feature Values')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.lineplot(data=feature_means, ax=ax2, palette='Set2', marker='o')\n",
    "ax2.set_ylabel('Average Value', color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df.to_csv(\"C:\\\\Users\\\\alexd\\\\Python Projects\\\\k_means/aggregated_data.csv\", index=False, encoding='ISO-8859-1')\n",
    "full_clustering_df.to_csv(\"C:\\\\Users\\\\alexd\\\\Python Projects\\\\k_means/full_clustering.csv\", index=False, encoding='ISO-8859-1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
